---
title: "STAT420 Zobreth Group Project"
author: "Brian Betancourt, Ethan Cook, Zongyu Li"
date: "2023-07-25"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# North American Video Game Sales Prediction

## Introduction
In this project, we assume the role of a video game company seeking to release games in the North American market for the first time. Given historical data regarding video game sales from other companies, we will use this data to predict our own successes (or follies) in the North American market and provide an informed decision to our company leadership regarding the potential risks in doing so.

### Exploring The Data


```{r}
library(faraway)
library(car)
vgsales = read.csv("vgsales.csv")
```

The data is stored as a `csv` file containing `r nrow(vgsales)` rows across `r ncol(vgsales)` columns (or predictors), and includes data from 1980 to 2020.


The data is largely "clean" and does not contain missing or "null" values, with the exception of the `Year` column which contains approximately `1.63%` null values.

```{r}
# null values per column
na_count = colSums(is.na(vgsales))
# proportion of NA values in each column
na_proportion = na_count / nrow(vgsales) * 100
# table/dataframe for readability
na_records = data.frame(Count = na_count, Proportion = na_proportion)
print(na_records)
```

We will also check for any unconventional data (i.e. non-numeric or date types in the `Year` predictor). 

Given that there appear to be a low number of records (271, or approximately 1.63% of the total dataset), we cast `Year` to be a numeric datatype for ease of use in modeling and we filter our dataset to remove these N/A records.
```{r}
# check non-numeric values in Year
unique(vgsales$Year[!grepl("^\\d+$", vgsales$Year)])

# count of "N/A" values in Year column
na_count = sum(vgsales$Year == "N/A")
# proportion of "N/A" values in Year column
na_proportion = na_count / nrow(vgsales) * 100

# print count and proportion
print(paste("Count of 'N/A' in Year: ", na_count))
print(paste("Proportion of 'N/A' in Year (%): ", na_proportion))

# filter the dataset
vgsales = vgsales[vgsales$Year != "N/A",]

# cast datatype
vgsales$Year = as.numeric(vgsales$Year)
```

It appear also that our `Year` values seem to trail off after 2016, so we can remove records from the dataset where year is > 2016
```{r}
# aggregate by year
global_sales_year = aggregate(Global_Sales ~ Year, vgsales, sum)

# plot
barplot(height = global_sales_year$Global_Sales, names.arg = global_sales_year$Year, xlab = "Year", ylab = "Total Sales (in millions)",main = "Total Sales (Global) by Year", las = 2,cex.names = 0.7) 

# filter dataset
vgsales = subset(vgsales, Year <= 2016)

```

The predictors have the following datatypes:

```{r}
str(vgsales)
```
- **Rank**: 
- *Name*: This is the title of a given video game
- *Platform*: This corresponds to the console the video game is released for
**Note**: It is possible that a video game may be released for more than one console simultaneously.
- *Year*: The year the video game was released
- *Publisher*: Company which published the video game
- *NA_Sales*: Number of sales in North America (in *millions of units sold*)
- *EU_Sales*: Number of sales in Europe (in *millions of units sold*)
- *JP_Sales*: Number of sales in Japan (in *millions of units sold*)
- *Other_Sales*: Number of sales in regions of the world outside of North America, Europe, and Japan (in *millions of units sold*)
- *Global_Sales*: Total Number of sales, globally (in *millions of units sold*)

#### Data Tendency

*What do sales look like, on average, for each geographic area and based on platform?*
```{r}
mean_sales_platform = aggregate(cbind(EU_Sales, JP_Sales, Other_Sales) ~ Platform, vgsales, mean)
print(mean_sales_platform)
```

**Assuming our company only cares about platforms from 2010 onward, we can focus on newer systems**

Below we can observe the average sales for each platform from 2010 to 2016
```{r}
# utilizing domain knowledge to filter platforms to only newer ones
new_platforms = c('X360', 'Wii', 'WiiU', 'XOne', 'PS3', 'PS4', 'PSV', '3DS', 'PC')
  # Filter data frame to include only specified platforms
vgsales_filtered = vgsales[vgsales$Platform %in% new_platforms, ]

mean_sales_platform_filtered = aggregate(cbind(EU_Sales, JP_Sales, Other_Sales) ~ Platform, vgsales_filtered, mean)
print(mean_sales_platform_filtered)

```


Of the newer platforms, which are most popular in each geographic region?
```{r}
# Find the platforms with highest mean sales in each region
highest_EU_platform = mean_sales_platform_filtered$Platform[which.max(mean_sales_platform_filtered$EU_Sales)]
highest_JP_platform = mean_sales_platform_filtered$Platform[which.max(mean_sales_platform_filtered$JP_Sales)]
highest_Other_platform = mean_sales_platform_filtered$Platform[which.max(mean_sales_platform_filtered$Other_Sales)]

highest_EU_sales = max(mean_sales_platform_filtered$EU_Sales)
highest_JP_sales = max(mean_sales_platform_filtered$JP_Sales)
highest_Other_sales <- max(mean_sales_platform_filtered$Other_Sales)

cat("Platform with highest mean sales in EU: ", highest_EU_platform, " (", highest_EU_sales, ")", "\n")
cat("Platform with highest mean sales in JP: ", highest_JP_platform, " (", highest_JP_sales, ")", "\n")
cat("Platform with highest mean sales in Other regions: ", highest_Other_platform, "(", highest_Other_sales, ")", "\n")
```

#### Data Distribution


Sales by Genre
```{r}
library(ggplot2)

# Aggregate total sales
eusales_agg = aggregate(EU_Sales ~ Genre, vgsales, sum)
jpsales_agg = aggregate(JP_Sales ~ Genre, vgsales, sum)
othersales_agg = aggregate(Other_Sales ~ Genre, vgsales, sum)

# EU Sales
ggplot(eusales_agg, aes(x = Genre, y = EU_Sales)) +geom_bar(stat = "identity", fill = "lightblue", color = "black") + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + labs(x = "Genre", y = "Sales (in millions)", title = "Total EU Sales by Genre")

# JP Sales
ggplot(jpsales_agg, aes(x = Genre, y = JP_Sales)) + geom_bar(stat = "identity", fill = "lightblue", color = "black") + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + labs(x = "Genre", y = "Sales (in millions)", title = "Total JP Sales by Genre")

# Other Sales
ggplot(othersales_agg, aes(x = Genre, y = Other_Sales)) + geom_bar(stat = "identity", fill = "lightblue", color = "black") + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + labs(x = "Genre", y = "Sales (in millions)", title = "Total Other Sales by Genre")

```



### Data Trends

Total Sales by Year and Geographic Region
```{r}
# convert year (currently chr)
vgsales$Year = as.numeric(vgsales$Year)

# 2010 onward filter
vgsales_current = vgsales[vgsales$Year >= 2010, ]

# Calculate total sales using the filtered data frame
total_sales_year = aggregate(cbind(EU_Sales, JP_Sales, Other_Sales) ~ Year, vgsales_current, sum)

library(ggplot2)
ggplot(total_sales_year, aes(x = as.numeric(Year))) +
  geom_line(aes(y = JP_Sales, color = "JP_Sales")) +
  geom_line(aes(y = EU_Sales, color = "EU_Sales")) +
  geom_line(aes(y = Other_Sales, color = "Other_Sales")) +
  labs(color = "Region", x="Year", y = "Total Sales", title = "Yearly Sales by Region")

```


Total Sales by Platform (2010-2020)
```{r}
library(ggplot2)

# year filter
vgsales_current = vgsales[vgsales$Year >= 2010 & vgsales$Year <= 2020, ]
total_sales_platform = aggregate(cbind(EU_Sales, JP_Sales, Other_Sales) ~ Platform, vgsales_current, sum)

ggplot(total_sales_platform, aes(x = Platform, y = JP_Sales)) +
  geom_bar(stat="identity") +
  theme(axis.text.x = element_text()) +
  labs(title = "Total JP Sales by Platform (2010-2020)", x = "Platform", y = "Sales")

ggplot(total_sales_platform, aes(x = Platform, y = EU_Sales)) +
  geom_bar(stat="identity") +
  theme(axis.text.x = element_text()) +
  labs(title = "Total EU Sales by Platform (2010-2020)", x = "Platform", y = "Sales")

ggplot(total_sales_platform, aes(x = Platform, y = Other_Sales)) +
  geom_bar(stat="identity") +
  theme(axis.text.x = element_text()) +
  labs(title = "Total Other Region Sales by Platform (2010-2020)", x = "Platform", y = "Sales")


```

## Methods
*This is the section where we fit and analyze models in order to represent the data*

### Pre-Processing
Several of our potential predictors are represented as characters, but we will want to convert them to factor variables. These include:  
* Platform  
* Genre  
* Publisher  
  
Previously we have filtered our dataset to only include games and platforms from 2010 on; next we'll make the character predictors into factors, then drop levels from factor variables that have no observations (i.e. levels that are only associated with data before 2010, such as Super Nintendo game data).

```{r}
# Factorize string predictors
vgsales_current$Platform = as.factor(vgsales_current$Platform)
vgsales_current$Genre = as.factor(vgsales_current$Genre)
vgsales_current$Publisher = as.factor(vgsales_current$Publisher)

# Remove unused factor levels
vgsales_modern = droplevels(vgsales_current)
```

I have also decided to  combine EU_Sales, JP_Sales, and Other_Sales into a new predictor called Non_NA_Sales This is because The sales in different countries are correlated, and Global_Sales is highly correlated with the others since it is an aggregation, which also includes NA_Sales. I am removing the combined columns for better viewing.

```{r}
# combine sales predictors into one
Non_NA_Sales = vgsales_modern$EU_Sales + vgsales_modern$JP_Sales + vgsales_modern$Other_Sales
vgs_modern = cbind(vgsales_modern, Non_NA_Sales)
vgs_modern = subset(vgsales_modern, select = -c(EU_Sales, JP_Sales, Other_Sales))

str(vgs_modern)
```

*Note:* The Year predictor will be tried as a numerical variable, but for our smaller range of years a factor might be more appropriate.

### Model Selection
*In this section, we choose a model which can represent the data most accurately*
- Perform any tests necessary to find correlation between variables (i.e. correlation matrix)

we will generate several models and compare metrics to give us a starting point on intuition.

```{r}
all_intr_mod = lm(NA_Sales ~ Platform * Year * Genre * Non_NA_Sales + Publisher, data = vgs_modern)
all_mod = lm(NA_Sales ~ Platform + Year + Genre + Publisher + Non_NA_Sales, data = vgs_modern)
foreign_sales_mod = lm(NA_Sales ~ Non_NA_Sales, data = vgs_modern)
intuitive_mod = lm(NA_Sales ~ Non_NA_Sales * Platform + Non_NA_Sales * Genre + Year, data = vgs_modern)
intuitive_mod2 = lm(NA_Sales ~ Non_NA_Sales * Platform + Non_NA_Sales * Genre + Non_NA_Sales * Publisher + Year, data = vgs_modern)
bic_back_mod = step(all_intr_mod, direction = "backward", trace = FALSE, k = log(nrow(vgs_modern)))
```

The intuitive models above were chosen using experience as a customer of video games and a previous salesman. The first, "intuitive_mod", posits that there are interactions between global non-NA sales and the platform/genre of the game. Platforms and genres can vary a lot in popularity and so I am accounting for different coefficients needed for the different factor levels.

The 2nd intuitive model, "intuitive_mod2", is similar to the first but includes an interaction between global non-NA sales and the video game publisher. This is based off of the understanding that there are big-name publishers that always produce more sales (profit not being a factor) and smaller independent publishers with more modest sales. As seen in later tests, this interaction gives the model a large boost in prediction accuracy without making it much more confusing.

With our models generated, let's get information on violated assumptions before producing results. I'll use the two models with the best prediction and interpretability combinations (metrics on prediction in later charts).
```{r}
par(mfrow = c(1, 2))
plot(fitted(intuitive_mod2), resid(intuitive_mod2), xlab = "Fitted", ylab = "Residuals", main = "Intuitive Model 2 Fit vs. Resid")
plot(fitted(bic_back_mod), resid(bic_back_mod), xlab = "Fitted", ylab = "Residuals", main = "BIC Backward Model Fit vs. Resid")
```

We see similar charts where there is a lot of variability regardless of fitted magnitude, but the less popularly selling games tend to be easier to predict. This also shows that the distribution of our data is far from normal, which we'll confirm below.

Now we will test the assumptions of a SLR model. Generating a Q-Q plot for each model yeilds very similar results, so I will only include the graph for the better performing intuitive model 2:
```{r}
qqnorm(resid(intuitive_mod2))
qqline(resid(intuitive_mod2), col = "red", lwd = 2)
stest = shapiro.test(resid(intuitive_mod2)[1:5000])
```
Clearly, the errors of our model are not normally distributed, as the plot shows trailing tails at both ends. The Shapiro-Wilkes test concurs by giving an extremely small p-value of `r stest$p.value`. *Note: we had to exclude 141 of the 5141 residuals dues to limitations of the shapiro.test function*.

## Results
*Numerical or graphical summaries of your results.*
*You should report a final model you have chosen. There is not necessarily one, singular correct model, but certainly some methods and models are better than others in certain situations. You may use any methods we studied this semester to complete this task, and provide evidence that your final choice of model is a good one. *

In the following figures, we show bar plots for the R^2 values and RMSE. We observe that for "all_intr_mod", "bic_back_mod" and "intuitive_mod" and "intuitive_mod2" have the highest R^2 values. For the RMSE bar plot, these 4 models also have the lowest RMSE. 

```{r}
# Given data
data <- data.frame(
  Model = c("all_intr_mod", "all_mod", "foreign_sales_mod", "intuitive_mod", "intuitive_mod2", "bic_back_mod"),
  R_Squared = c(summary(all_intr_mod)$adj.r.squared, 
              summary(all_mod)$adj.r.squared, 
              summary(foreign_sales_mod)$adj.r.squared, 
              summary(intuitive_mod)$adj.r.squared, 
              summary(intuitive_mod2)$adj.r.squared,
              summary(bic_back_mod)$adj.r.squared),
  RMSE = c(sqrt(mean(resid(all_intr_mod) ^ 2)), 
            sqrt(mean(resid(all_mod) ^ 2)), 
            sqrt(mean(resid(foreign_sales_mod) ^ 2)), 
            sqrt(mean(resid(intuitive_mod) ^ 2)), 
            sqrt(mean(resid(intuitive_mod2) ^ 2)), 
            sqrt(mean(resid(bic_back_mod) ^ 2)))
)

# Reshape the data to a long format using gather (tidyr)
data_long <- data %>%
  gather(metric, value, -Model)

# Install and load required libraries (if not already installed and loaded)
# install.packages("ggplot2")
library(ggplot2)

# Bar plot for R_Squared
ggplot(data_long[data_long$metric == "R_Squared", ], aes(x = Model, y = value)) +
  geom_col(fill = "blue") +
  labs(x = "Model", y = "R_Squared") +
  ggtitle("R_Squared for Different Models") +
  theme_minimal()

# Bar plot for RMSE
ggplot(data_long[data_long$metric == "RMSE", ], aes(x = Model, y = value)) +
  geom_col(fill = "green") +
  labs(x = "Model", y = "RMSE") +
  ggtitle("RMSE for Different Models") +
  theme_minimal()

```

Looking at the above charts values, we see the large model with many fully interacting predictors has the best metrics. This is unsurprising, since adding more and more predictors and interactions generally produces better predictions, but can become confusing and loses ability to interpret meaning between variables.

To conduct a comprehensive comparison of the four models, namely "all_intr_mod", "bic_back_mod" and "intuitive_mod" and "bic_back_mod2". We conducted ANOVA tests on each pair of them. From the following tables, we see that all p-values are significant. A positive "Sum of Sq" indicates that Model 1 explains more variance than Model 2. Conversely, a negative "Sum of Sq" indicates that Model 2 explains more variance than Model 1. By referring to the table, we have "all_intr_mod" having better performance than "bic_back_mod", "intuitive_mod" and "intuitive_mod2". Then we have "intuitive_mod2" having statically  better performance than "bic_back_mod" and "intuitive_mod1". In the end, we have "bic_back_mod" having better performance than "intuitive_mod1". In summary, we can rank the best performing modeling to the least performance model as following "all_intr_mod">"intuitive_mod2">"bic_back_mod">"intuitive_mod1". 


```{r}


# Perform ANOVA between all_intr_mod and bic_back_mod
anova1 <- anova(all_intr_mod, bic_back_mod) #(all intr)

# Perform ANOVA between all_intr_mod and intuitive_mod
anova2 <- anova(all_intr_mod,intuitive_mod) # (all_intro)

# Perform ANOVA between all_intr_mod and intuitive_mod2
anova3 <- anova(all_intr_mod, intuitive_mod2)  # (all_intro)

# Perform ANOVA between bic_back_mod and intuitive_mod
anova4 <- anova(bic_back_mod,intuitive_mod) # (back)

# Perform ANOVA between bic_back_mod and intuitive_mod2
anova5 <- anova(bic_back_mod,intuitive_mod2) # (intuitive_mod2)

# Perform ANOVA between intuitive_mod and intuitive_mod2
anova6 <- anova(intuitive_mod, intuitive_mod2) # (intuit 2)

# Extract ANOVA results
print(anova1)
print(anova2)
print(anova3)
print(anova4)
print(anova5)
print(anova6)

```

The "all_intr_mod" model's improved performance can be attributed to its inclusion of the interaction terms, which allowed for a more accurate and nuanced representation of the relationship between the predictors and the response variable, NA_Sales. 

## Discussion
In the context of our original business problem, the results indicate that it (IS/IS NOT) in the interest of our video game company to enter the North American market. This conclusion is informed by:
- Reason A
- Reason B
- Reason C

*In this paragraph, we can explain Reason A* We can use graphics here as necessary, and we can explain the significance of this graph/test/analysis in the context of our company.

*In this paragraph, we can explain Reason B* We can use graphics here as necessary, and we can explain the significance of this graph/test/analysis in the context of our company.

*In this paragraph, we can explain Reason C* We can use graphics here as necessary, and we can explain the significance of this graph/test/analysis in the context of our company.

## Appendix
Should contain code and analysis that is used, but that would have otherwise cluttered the report or is not directly related to the choice of model. Do not simply dump code in here. Only utilize the appendix to supplement the primary focus of the report. The appendix should also conclude with the names of the group members.

### Ethan Cook, Brian Betancourt, Zongyu Li